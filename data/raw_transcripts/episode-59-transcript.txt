Thank you for wanting to know more today than you did yesterday, and I hope you love the show. So, if you’ve been listening to this show for at least a descent amount of time, you’ve probably noticed something about philosophers in general by this point. These people just love their thought experiments, don’t they? Thought experiments are an important part of philosophy. See, as you know, philosophy oftentimes tries to get us to think about ourselves and the world in a slightly different way than we typically would, the goal being that hopefully after doing these things, we can hack past the absolute jungle of social conventions and prejudices and all these things that have been meticulously programmed into us since birth to hopefully get a more honest depiction of reality, not just a depiction of reality that has our particular culture and time period’s stamp of approval branded into it. And whenever somebody asks us to consider ourselves in the middle of one of these thought experiments, it’s so easy to be dismissive of the entire process, isn’t it? It’s so easy to not take a thought experiment seriously in the moment because, well, they’re not real. This is something I’ve encountered quite a bit when it comes to ethical dilemmas in particular like the axe murderer example from last episode or the kind of things we’re going to be talking about today. People will say things like, “What’s the point? Like, what’s the point of considering these things? What’s the point of being whisked away into your little fantasy world? I’m a serious person. I got both my feet on the ground here. I don’t need to understand the fundamental reasons behind why I make the moral judgments I do. I live my life. I take all the information available to me in the moment. And I just use common sense, simple as that.” But in the words of the great Abraham Lincoln, the great philosopher Abraham Lincoln, common sense is just a collection of prejudices that you’ve arrived at before the age of 18. Fact is, people make decisions for specific reasons, not because they’re appealing to this elusive thing that they call common sense that’s just somehow the right answer in every situation. No, when you cite things like common sense or sound moral reasoning as the justification for why you made a decision that you did, you still are making that decision based on something. You still may be making a decision based on deontology or consequentialism or anything for that matter; you’re just using this term “common sense” as a catch-all euphemism. And you know, that’s the other side of this. Last episode I went on a bit of a nerd tangent where I talked about all the perks of arriving at a satisfying definition for all this stuff. I talked about the potential fruits of laboring away in these ethical dilemmas and how you might over time eventually arrive at some clarity about why you personally deem certain things to be right or wrong. But just be warned from this point forward. The exact opposite might happen as well. Because if you’re anything like me, I mean, I started thinking about this stuff, and I thought I had it all figured out. I mean, I thought I had an iron-clad understanding of what makes something right or wrong. But what ended up happening with me is the more I read, the more I started thinking about all the contingencies, all the different individual circumstances; instead of gaining clarity, I started questioning myself more. I started finding exceptions to all my so-called iron-clad rules. I started to get confused. I started to realize that this thing that we call morality, this process that we call ethics—not as cut and dry as I once thought. Sometimes things are not as simple as just “This decision was right, and this decision was wrong.” It’s sometimes not as simple as just “This guy was a saint for doing what he did, and this guy over here was a complete monster for doing what he did.” In fact—and it was a very unexpected byproduct of this whole process when it happened. I didn’t realize it was going to happen—after thinking about these things long enough, for some reason I stopped thinking about people as saints and monsters altogether. I just stopped. And it was weird. It felt like the same sort of mental graduation that a four-year-old might have when they stop believing in monsters under their bed. I stopped believing in monsters. Maybe this is why I take issue with the people that talk about morality as though it’s this definitive collection of adjectives that you can hang on the wall somewhere. Those people have not been through the baptism by fire. It’s just so obvious when you talk to them. These people have never run their beliefs through the rigors of these ethical dilemmas. These people are not confused enough. And I guess to tie this all together, what I will say is that if there’s one thing philosophy has taught me over the years it’s that confusion on a given subject is not always a step backwards. The point is, even if you’re one of these people, even if you’re super confident about why you make the moral judgments you do, oftentimes you learn a lot about yourself when putting yourself through these ethical dilemmas. Oftentimes you quickly realize that just by asking a few very simple questions that whatever this thing is that you use to make your moral judgments, whatever this thing is that you’re super confident in, it can be very difficult to define. Now, that said, if you consider yourself a fan of philosophy, there are certain infamous thought experiments that you’ve just heard before. These are thought experiments that everybody’s heard about. If you’re at some sort of hoity-toity philosophy party and you walk up to some guy with a monocle and you start talking to him about it, that guy’s going to know what you’re talking about. And let’s continue to learn more about ourselves and more about where we stand ethically when talking about this period in time by putting ourselves through one of the most famous of all the famous thought experiments of philosophy. It’s known as the trolley car problem, and it goes like this. I want you to imagine you’re the conductor of a trolley car. Now, hold on, before you go getting all excited about your new prestigious career as a trolley car conductor, I want you to imagine you’re the conductor of a broken trolley car. That’s right. Back down a couple of pegs. Anyway, you’re conducting this thing down the tracks one day, and the breaks stop working. It’s now a runaway trolley car—runaway trolley car. Hm, I said that like I was British. Now, to make matters worse, when you’re in this broken, brakeless trolley car, you look ahead of you a few hundred feet, and to your horror, you see five people standing on the tracks, completely unaware that this runaway trolley car is hurling towards them at 60 miles an hour. In the moment, it seems like there’s nothing you can do. You can’t stop the trolley car. It has no brakes. It seems like no matter what you do, it’s going to run into the five people. It will kill them all most certainly. What a horrible tragedy it will be. But then you realize something. You realize that you can switch the trolley car onto a different track, an adjacent track. You know those little junctions that they have, the lever that you can pull, and it switches the trolley onto a different track? One of those. But just as soon as you realize that you can switch tracks and save these five people, you realize that on that new track that you’re about to switch to is just one person who is also completely unaware of what’s going on. And they will inevitably get turned into a trolley pancake if you so decide to switch the tracks. What do you do? What do you do? Do you allow the trolley to kill the five people? Or do you switch the tracks, pull the lever, and opt to kill just one person? What decision would you make in that moment? And look, just for the record, given the audience of this show, just given who’s listening to this right now, I have full confidence that you guys came up with some sort of diabolical plan where you don’t got to kill anyone here. But if we’re just talking statistically, the layman, statistically speaking, most people say that in this moment what they would do is they would pull the lever, switch the tracks, and favor killing the one person over the five. And this is totally understandable, right? In fact, come to think of it, I think I can get on board with that. In fact, I would pull that lever. You guys, I am not confused about morality anymore. I’m not afraid anymore! I mean, after all, one person dying is a much better outcome than five people dying. I mean, to me, this seems really straightforward. If you have the opportunity to, why wouldn’t you save the five? I’m sure you remember from last episode. What I’m doing here is I’m looking at the situation through the eyes of a consequentialist. And if you wanted to go a step further than that, I might be looking at this through the eyes of a utilitarian. Utilitarianism is a specific type of consequentialism developed by a guy named Jeremy Bentham, refined by a guy named John Stuart Mill. But the fundamental idea at its core is something that we’ve talked about on this podcast going all the way back to the Hellenistic period with the Epicureans: the idea being that what is right or what is good is always the action where the consequences of that action maximizes utility; hence the name utilitarianism. “What is utility?” you may ask. Well, utility can be a lot of different things. It can be emotional wellbeing. It could be economic wellbeing. It could be the limitation of suffering. But most of the time people just define it as pleasure. This is a very simple idea that on the surface sounds absolutely incredible. Jeremy Bentham looked at nature around him, much like the Epicureans did, and he realized that, “Nature has placed mankind under the governance of two sovereign masters, pain and pleasure.” That’s the famous line by him. Anyway, human action can be distilled down into two things: an avoidance of pain and the pursuit of pleasure. To a utilitarian, the right decision in any situation is just the one where the consequences ensure the greatest about of utility to the greatest number of people. The right thing to do is the thing that maximizes happiness for the greatest number of people. Back to the trolley car example. Sounds like I’m a utilitarian now. After all, it seems very straightforward what the right decision is here. I would pull the lever, kill the one person in favor of killing the five people. If we’re judging the right or wrong decision in terms of it bringing the greatest utility to the greatest number of people, then killing one to save five, I mean, that’s as easy as it gets. That’s a no-brainer. Man, I got to be honest with you guys. It feels good to be confident in why you’re making moral decisions. I can see why this is addictive. It feels great. Can I just tell you guys something? It feels great to just be able to pull levers and kill people with impunity. But as great as this feels—my cruel mistress philosophy—it always manages to throw a monkey wrench in the equation, right? That’s not where the trolley car problem ends. At that point, the trolley car takes a turn—no pun intended—and it asks you to consider a slightly different scenario than the first one. This time, imagine you’re still in the general vicinity of the trolley tracks, but now you’re up on a bridge, a bridge that overlooks the tracks. So, now you’re an observer. Now, while looking down and observing the train track area, you notice a very similar situation to the first one unfolding, except this time there’s only one track. There’s five oblivious people standing on the train tracks, not paying attention, a couple hundred feet away from a runaway trolley hurling towards them. And it seems like in the moment there’s nothing you can do to save these people from certain death, when all of a sudden you look over to your right, and you notice something. There’s a fat guy standing next to you, leaning over the side of the bridge, trying to get a look at what’s going on below, much like you are. Now, I realize this may seem slightly ridiculous, but in the thought experiment we’re supposed to imagine that this guy is not just your run-of-the-mill, garden-variety fat guy. This guy’s grotesquely fat, so fat that you could push him over the side of the bridge, and when he hit the ground and died, it would create some sort of shock-wave situation where the five people would be alerted to his presence. They would see the train coming; they would jump off the tracks. His sheer girth would slow down the train long enough to make sure that all of them got out of the way. Either way, you kill one person to save five. What do you do? Do you push the guy over the bridge to save the five innocent people? Well, I got to be honest with you guys. Right now, I’m not having too much fun going through the whole process of this thought experiment. I mean, I’m not sure how aware of my situation you guys are, but I just converted to utilitarianism recently, and I’m having a little bit of a crisis of faith right now. See, as a good utilitarian, if I’m just looking at the consequences of my actions and whether they bring the greatest amount of utility to the greatest number of people, well, the answer seems to be very cut and dry here. I need to push my new sizeable friend over the bridge, kill him inevitably, but save the five. But it just feels wrong to me for some reason. Now, statistically speaking, most people after being advocates of pulling the lever in the first scenario would never even think about pushing the fat guy over the bridge. And I think I seem to fall into the same category here. Why do I feel different about this scenario than the first one? What really is the difference between the two situations? Now, obviously there are differences between the two. I mean, you wouldn’t be able to ask, “What’s the difference between these two things?” if there weren’t actually differences between those two things. Kind of confusing whenever people say, “What’s the difference between these two…”—anyway, in both cases, your behavior remains remarkably similar. You are actively sentencing one innocent person to death in the name of saving five innocent people. Now, here it’s very tempting to give all sorts of rebuttals. “Yeah, I was down for pulling the lever before—before, when my actions only involved people who were already on the tracks to begin with. Ah, that’s what’s different. These people were in harm’s way. To push the guy over the bridge is to bring an innocent bystander into harm’s way. How could I ever do that just to save five people? That’s not fair to him.” But is that true? In the original example, was the one person that you opted to kill by pulling the lever in harm’s way before you pulled the lever? They had no reason to assume the train would take some unexpected diversion at the last second onto their track that was otherwise completely safe. They were completely out of harm’s way until you decided to pull the lever and put them into harm’s way. If it weren’t for your decision to pull the lever, that track was equally as benign as standing on a bridge overlooking the tracks. Now, another rebuttal might be, “Well, pushing someone over the side of a bridge is much, much different than merely pulling a lever. In one case you’re just pulling a lever, and something happens after you pull that lever. In the other case, well, now you’re physically putting your hands on the guy. You’re forcing him over the side of a bridge. That is murder. That physical contact makes it much different.” But is it really the physical contact that makes it different? I would argue that it’s not. I mean, what if instead of pushing the guy over the side, you could do something else? What if you could pull a lever, and the fat man would be launched out of some sort of medieval trebuchet, and he would land on the tracks, and the same exact thing would happen? Would you feel morally justified to do that? Personally, I wouldn’t. And I think if this illustrates anything, and the point of this, is that there must be something else at work here, something other than just the physical contact that makes us think that this action is wrong and the other one is right. I think most people would say that regardless of the consequences, there’s something unique about pushing the fat guy over the bridge that’s just wrong, something that isn’t present in the lever-pulling example. Now, the really fascinating thing here that we should all take from this is not that we make different decisions given different individual situations. That’s obvious. The interesting thing is that at the beginning of this thought experiment I started out pretty darn confident—didn’t I?—pretty confident in my decision-making about pulling that lever. I cited very clear reasons for why what I did was perfectly okay in that situation. And then with just a few minor tweaks to the circumstances, all of a sudden, I started to revise my entire moral foundation. I started giving different reasons, which either makes me ignorant, a liar, a hypocrite, or more likely it implies that the reason I gave for why I made the first decision to pull the lever was not the real reason why I did it. There’s something more complicated at work here. What is that thing? There have been many attempts to answer this question over the years. As we talked about last time, the deontologist would say that regardless of what the consequences of our actions will be—or in this case, inaction—although the consequences are bad, some things are just wrong, like, for instance, pushing an innocent fat guy over the side of a bridge. Look, let’s get one thing clear. In both scenarios if we do nothing, five people die. There’s no getting around that. And just you knowing the certain outcome in either situation instantly implicates you. It leaves you in a place where you need to make a choice. Doing nothing in these cases does not absolve you from any guilt. Consequentialists would say that the ends justify the means, but a deontologist, someone like Immanuel Kant, would say that you should never use people as a means to some end. When you push the innocent fat man over the side of a bridge to save the five people, you are using that guy as a means to some end that you aim to achieve, and that is wrong. Immanuel Kant talks about the ideal society that we could live in as what he calls a kingdom of ends where every person is viewed not as a means to some end or a pawn in someone else’s game that they’re playing where they can say, “Oh, this guy’s just a means to an end.” Every person is an end in themselves, as Kant says. Now, we’ll talk in a second more fully about why this point that Kant’s making here is important. But first, let’s talk about how Kant may have responded here, alright? How would he have responded to the apparent contradiction between me thinking it’s okay to pull the lever to kill the person but it’s wrong to push the guy off the bridge to kill the person? See, Kant was smart. Well, to say the least, he was smart. He recognized that it would be very easy for us to mistake whatever cultural norms we were born into for a good, solid moral foundation. Not many people would think that chopping the hands off of somebody that just stole a Snickers bar would be a fair punishment. But if Snickers bars existed back in Babylonia, well, you might find quite a few people that disagreed with you at the time. So, to circumvent this transient, subjective moral trap that we might otherwise fall into, as we talked about last episode, Kant thinks that just like our objective conception of reality itself is based on a priori concepts of reason, our morals too can be based on a priori concepts of reason. Now, let’s slow down and think about what this means for a second. This doesn’t just mean that these moral principles that we’re going to arrive at need to be appropriate for every human in every time period and in every circumstance, but for these things to be truly valid, they need to be done purely from a place of being moral. For example, from the last episode, the kid that only cleans his room because his mom says he’s going to get an ice cream cone if he does it—that’s not good enough for Kant. So, given these criteria, these criteria that Kant’s laid out for what a moral action can be, let’s try to come up with a few. What are some moral principles that fit all these criteria that we just talked about? Can you think of any? Because I can’t. I mean, this is a pretty intense set of restrictions to put on the process. Kant’s obviously taking these moral principles very seriously. See, Kant argues that if you’re ever doing anything in this world, any action you take is going to be done with certain things in mind. It’s going to be done at a particular place in time. It’s going to be yielding to a particular set of circumstances. It’s going to be considering a particular history given your own particular personality. Think about this point he’s making. These elements of any action that we ever take are inescapable. They’re inescapable aspects of our existence. This is the reason why he looks to things that are prior to experience, prior to tradition, prior to circumstances, prior to your personality. It’s for this reason that Kant says that the only things that would ever fit into this rigorous set of criteria are a priori. The moral principles that I should adhere to in determining whether to push the fat guy over the bridge or not—they have to be a priori in nature. Remember, moral action is determined by reason for Kant. Reason is the same in all rational beings regardless of time period or culture. So, because reason is universal, morality too should be universal. So, once you arrive here, if you’re Kant, you still have a pretty difficult task ahead of you. Well, where Kant goes from here—his solution to the problem—is what he calls his categorical imperative. Categorical imperative—I know, two really cool sounding words that if you break them down individually, they actually do a pretty good job at explaining what Kant’s talking about with his categorical imperative: categorical meaning explicit or applying across all categories, and imperative meaning essential or necessary. An essential rule of morality that applies across every situation, culture, time period, set of experiences, you name it. Now, Kant gives multiple formulations of his categorical imperative, but by far the most famous one is this. “There is only a single categorical imperative, and it is this: act only on that maxim through which you can at the same time will that it should become a universal law.” Now, what Kant’s saying here is that before you do anything, anything, consider something for a second. Consider for a second what the world would look like if literally every other person in the entire world acted just as you did in that situation. Really imagine it. And if that world that you imagine is not something that you’re willing to deal with, if it’s a direct contradiction for that world to exist or if that world would be filled with chaos, then you shouldn’t do whatever it is you were considering doing. Let’s think of a few examples of what he’s talking about. Someone cuts you off in traffic. What do you do? Well, if you decide to chase the guy down and kill him, Kant would want you to ask, how would the world look if every time someone got cut off in traffic just as I did, the person that got cut off chased the other person down and killed them? That world would be absolute chaos, wouldn’t it? People would be terrified of driving. That’s for sure. Productivity would go way down. And heaven forbid you just lose focus on the road for one second and accidentally cut someone off. You would be dead. You wouldn’t want to live in that world. But how about something less extreme? Let’s say you’re standing outside of a supermarket, and you’re drinking a Coke. You’re waiting for a ride or something. You finish your bottle, and you decide instead of walking all the way to the trashcan, you’re just going to leave it on the ground by where you were standing. Someone will get it eventually, right? Well, if we apply Kant’s categorical imperative to this example, the world would be an ocean of Coke bottles everywhere. Think if seven billion people, just whenever they got done with their trash, they just left it wherever they were when they got done using it. Just think of how that world would look. Aside from us all existing in a perpetual revolving trashcan, think of the burden to the average taxpayer, including you, by the way. We’d have to spend millions and millions of your hard-earned dollars on teams of people constantly patrolling around just picking up people’s garbage. It would be madness. Do you understand what he’s saying? See, this is the sort of thinking behind why Kant thinks it’s a bad idea to lie. It’s just downright illogical, because if we existed in a world where all anyone ever did was lie, then everyone would always know that they were being lied to. So, they could never be deceived. But that’s kind of the point of a lie, to deceive people. So, logically, it would be pointless. Now, you contrast that with a world when everybody always told the truth, and there’s no logical contradiction. So, right now I want to tie this all together into a neat package because it’s kind of been spread across two episodes. Let’s bring it all together here. To Kant, when considering whether to push the innocent fat guy off the bridge in order to save the five people, or when considering any sort of ethical dilemma for that matter, he would want us to consider these five things. Number one, reason. Our actions need to be guided by our own reason, not our senses, not our experiences, not our cultural norms or anything like that. Number two, it needs to be autonomous. We need to be acting freely. In order for us to be acting freely, we can’t be enslaved to something. We can’t be enslaved to some overseer that has decreed a moral code for us to follow. We can’t be enslaved to an ice cream cone that our mom told us we’ll get if we do something moral. Three, we need to treat ourselves and others as ends in themselves, not as means to some end that we want to achieve. In other words, we can’t manipulate people. We can’t lie to people. Because when we do that, we are by definition withholding valuable information from them, and we’re doing it so that they will make a decision that they might otherwise not make if they had all the facts. In this way, Kant thinks that you’re robbing them of something. You’re robbing them of their ability to make a fully rational choice. And if you’re robbing them of their ability to reason, you’re robbing them of a piece of their humanity. Four, we should act only in accordance with moral principles where we’d be satisfied if they were made into a universal maxim. I.e., if everyone did this thing, how would the world look? It’s what we just talked about. Number five, we should strive to live in the kingdom of ends which, now that I think about it, is too complicated for this five-bullet-point format that I just created on the fly. But it has to do with the political implications of all this stuff that we’ve been talking about. So, to wrap it up, it’s very easy to be dismissive of thought experiments. It’s very easy to be dismissive of asking ourselves questions about why we make the moral judgments we do. But the advantages of putting yourself through these thought experiments are more than just understanding yourself better or living a more fulfilling life. These things inevitably extend to practically every decision we make as a society about what’s right or wrong. See, it’s so tempting to say things like, “Murder is just wrong. Case closed.” “Stealing is just wrong.” “I’m just going to pull the lever, kill the one person instead of the five. That’s just common sense. No need to consider any other alternatives. No need to understand why I make the moral judgments I do.” Well, maybe that’s good enough for you. But the reality is that the world at large is not always that black and white. Things like murder trials and economic policy and whether to become involved in a war or what a just war is at all or foreign policy or civil rights—the ethical decisions at the root of these massive issues that we face as a society—these aren’t things that you can just adhere to moral commandments about. These things aren’t as simple as just, “Oh, a guy stole an ox from his neighbor. We need to punish him. Let’s consult our rules that we have.” The world is filled with millions of these nuanced gray areas that need to be accounted for. Yes, sometimes the only thing that’s at stake is your time. Yes, sometimes it’s just a dumb podcast asking you to be whisked away into a fantasy world. But in other cases, it’s only by considering these details that we can get a more accurate understanding of what we really value as a species, to understand why we really pulled that lever. It’s for the times when literally millions of lives might hang in the balance, including yours. Thank you for listening. I'll talk to you next time.